# A/B 테스트 워크플로우 (Type D)

## 개요
데이터 기반 의사결정을 위한 체계적인 A/B 테스트 워크플로우.
CREATIVE_TEAM + ANALYTICS_TEAM 협업을 중심으로
가설 수립 → 변형 설계 → 법적 검수 → 실행 설정 → 모니터링 → 통계 분석 → 승자 적용까지 커버한다.
크리에이티브, 키워드, 타겟팅, 입찰, 랜딩 페이지 등 다양한 요소를 테스트할 수 있다.

---

## 트리거

| 조건 | 예시 | 판단 기준 |
|------|------|----------|
| 크리에이티브 테스트 | "어떤 카피가 나을까?", "소재 테스트 해보자" | 카피/이미지 변형 비교 |
| 타겟 테스트 | "2030 vs 3040 누가 반응 좋을까" | 오디언스 세그먼트 비교 |
| 채널 테스트 | "네이버 vs 구글 어디가 나을까" | 채널 효율 비교 |
| 입찰 테스트 | "수동 vs 자동 입찰 뭐가 나아" | 입찰 전략 비교 |
| 랜딩 페이지 테스트 | "LP 두 개 중 어디가 전환 높아" | LP 전환율 비교 |
| 최적화 과정에서 | 최적화 워크플로우 내 테스트 필요 시 | 개선 가설 검증 |

---

## 프로세스

```
[오너 요청 또는 최적화 과정에서 발생]
         ↓
[TEAM_LEAD] 접수 + 테스트 유형 판단
  → 테스트 대상 확인 (카피/타겟/채널/입찰/LP)
  → 테스트 규모 결정 (소규모/중규모/대규모)
         ↓
[Phase 1: 가설 수립] (담당 서브팀/에이전트 + INSIGHT_ANALYST)
  → INSIGHT_ANALYST: 현재 상태 분석 (베이스라인)
  → 담당 서브팀/에이전트: 테스트 가설 정의
  → INSIGHT_ANALYST: 성공 기준(Primary Metric) 설정
  → INSIGHT_ANALYST: 보조 지표(Secondary Metrics) 설정
  → INSIGHT_ANALYST: 최소 샘플 사이즈 산출
  → 산출물: A/B 테스트 계획서
         ↓
[Phase 2: 변형 설계] (담당 서브팀/에이전트)
  │
  ├─ 카피 테스트 → CREATIVE_TEAM
  │   → COPYWRITER: 변형 카피 작성 (2~5개)
  │   → CREATIVE_REVIEWER: 법적/정책 검수 (모든 변형)
  │
  ├─ 타겟 테스트 → KEYWORD_AUDIENCE_TEAM
  │   → AUDIENCE_RESEARCHER: 오디언스 세그먼트 변형 설계
  │   → TREND_ANALYST: 세그먼트 시장 규모 검증
  │
  ├─ 입찰 테스트 → BID_OPTIMIZER
  │   → 입찰 전략 변형 설계
  │
  └─ 채널 테스트 → CHANNEL_TEAM (해당 채널 전문가)
      → 채널별 세팅 설계
  │
  → 산출물: 변형 설계서
         ↓
[Phase 3: 테스트 설정 및 실행] (CHANNEL_TEAM - 해당 채널 전문가)
  → 해당 채널 전문가가 테스트 설정
  → 트래픽 배분 설정 (균등)
  → 트래킹 설정 (테스트별 UTM)
  → 테스트 시작
  → 산출물: 테스트 실행 확인서
         ↓
[Phase 4: 모니터링] (DATA_MONITOR)
  → 일간 성과 모니터링
  → 이상 발생 시 즉시 알림 (TEAM_LEAD + 담당 서브팀)
  → 통계적 유의성 추적
  → 최소 실행 기간 확인
  → 산출물: 일간 모니터링 로그
         ↓
[Phase 5: 결과 분석] (INSIGHT_ANALYST + 담당 서브팀/에이전트)
  → INSIGHT_ANALYST: 테스트 종료 판단 (유의성 또는 최소 기간)
  → INSIGHT_ANALYST: 통계적 유의성 검증 (p-value < 0.05)
  → INSIGHT_ANALYST: 변형별 성과 비교
  → INSIGHT_ANALYST: 승자 판정
  → 담당 서브팀: 부가 인사이트 도출 ("왜 이 변형이 이겼는가")
  → 산출물: A/B 테스트 결과 리포트
         ↓
[Phase 6: 승자 적용] (CHANNEL_TEAM - 해당 채널 전문가)
  → 승자 변형을 전체 트래픽에 적용
  → 패자 변형 중단
  → 변경 사항 기록
         ↓
[TEAM_LEAD] 오너에게 결과 보고
  → 테스트 요약
  → 승자 및 근거 (통계적 유의성)
  → 다음 테스트 제안
```

---

## A/B 테스트 설계 원칙

### 핵심 원칙

```
1. 한 번에 하나의 변수만 변경한다
   → 여러 변수 동시 변경 시 어떤 변수가 원인인지 알 수 없음
   → 다변량 테스트(MVT)는 별도 프레임워크

2. 통계적 유의성을 달성할 때까지 실행한다
   → 최소 95% 신뢰구간 (p-value < 0.05)
   → 조급하게 중단하면 잘못된 결론
   → INSIGHT_ANALYST가 통계적 검증 담당

3. 충분한 샘플 사이즈를 확보한다
   → 최소 변형당 1,000 노출 (디스플레이/소셜)
   → 최소 변형당 100 클릭 (검색)
   → 최소 변형당 30 전환 (전환 최적화)
   → INSIGHT_ANALYST가 사전에 최소 샘플 산출

4. 외부 변수를 통제한다
   → 테스트 기간 동안 다른 변수 고정
   → 시즌/이벤트 기간 피하기 (혼재 변수) — TREND_ANALYST 확인
   → 동일 기간, 동일 타겟에 동시 노출

5. 테스트 전에 가설과 성공 기준을 정한다
   → "이기면 적용"이 아닌 "왜 이길 것인지" 근거
   → 1차 지표(primary) + 2차 지표(secondary) 사전 정의

6. 법적/정책 검수를 거친 변형만 테스트한다
   → CREATIVE_REVIEWER PASS 판정 없는 크리에이티브 변형은 테스트 불가
```

### 테스트 규모 기준

| 규모 | 예산 | 기간 | 변형 수 | 사용 상황 |
|------|------|------|---------|----------|
| 소규모 | 전체 예산의 10~15% | 3~7일 | 2개 | 카피/소재 빠른 검증 |
| 중규모 | 전체 예산의 15~25% | 7~14일 | 2~3개 | 타겟/입찰 전략 검증 |
| 대규모 | 전체 예산의 25~40% | 14~28일 | 2~5개 | 채널/전략 대전환 |

---

## 테스트 유형별 상세

### 1. 크리에이티브 A/B 테스트 (CREATIVE_TEAM + INSIGHT_ANALYST)

```
[테스트 계획서]
가설: "{변형B}가 {변형A}보다 {지표}가 높을 것이다. 이유: {근거}"
1차 지표: CTR
2차 지표: CVR, CPA
변형:
  A (컨트롤): {현재 카피/소재}
  B (챌린저): {COPYWRITER가 작성한 변형 카피/소재}
법적 검수: CREATIVE_REVIEWER PASS 확인
트래픽 배분: 50:50
최소 기간: 7일
최소 샘플: 변형당 1,000 노출
채널 설정: 해당 채널 전문가가 설정 (동일 오디언스, 동일 예산, 동일 일정)
```

#### 크리에이티브 테스트 변수 예시
| 테스트 변수 | 변형 A | 변형 B | 측정 지표 | 담당 |
|------------|--------|--------|----------|------|
| 헤드라인 톤 | 혜택 중심 | 문제 제기 | CTR | COPYWRITER |
| CTA 문구 | "지금 구매" | "무료 체험" | CVR | COPYWRITER |
| 숫자 표현 | "50% 할인" | "반값" | CTR | COPYWRITER |
| 긴급성 | "오늘만" | "이번 주" | CVR | COPYWRITER |
| 사회적 증거 | "10만명 선택" | 없음 | CTR, CVR | COPYWRITER |
| 이미지 스타일 | 제품 사진 | 라이프스타일 | CTR | VISUAL_DIRECTOR |

### 2. 오디언스 A/B 테스트 (KEYWORD_AUDIENCE_TEAM + INSIGHT_ANALYST)

```
[테스트 계획서]
가설: "{오디언스B}가 {오디언스A}보다 {지표}가 높을 것이다. 이유: {근거}"
1차 지표: CPA 또는 ROAS
2차 지표: CVR, 전환수
변형:
  A (컨트롤): {현재 오디언스 - AUDIENCE_RESEARCHER 설계}
  B (챌린저): {변형 오디언스 - AUDIENCE_RESEARCHER 설계}
시장 검증: TREND_ANALYST 세그먼트 규모 확인
트래픽 배분: 예산 50:50
최소 기간: 14일
최소 샘플: 변형당 30 전환
채널 설정: 해당 채널 전문가가 설정 (동일 소재, 동일 입찰, 동일 일정)
```

### 3. 입찰 전략 A/B 테스트 (BID_OPTIMIZER + INSIGHT_ANALYST)

```
[테스트 계획서]
가설: "{입찰B}가 {입찰A}보다 {지표}가 높을 것이다. 이유: {근거}"
1차 지표: CPA 또는 ROAS
2차 지표: 전환수, 비용
변형:
  A (컨트롤): {현재 입찰 전략}
  B (챌린저): {BID_OPTIMIZER가 설계한 변형 전략}
배분: 캠페인 복제 (50:50 예산)
최소 기간: 14일 (입찰 학습 기간 포함)
최소 샘플: 변형당 50 전환
주의: 메타 학습 단계(Learning Phase) 고려 — META_SPECIALIST 확인
```

---

## 테스트 종료 기준 (INSIGHT_ANALYST 판단)

### 통계적 유의성 달성
```
조건: p-value < 0.05 (95% 신뢰구간)
판정:
├── 유의미한 차이 있음 → 승자 판정 → 적용
├── 유의미한 차이 없음 → 무승부 → 컨트롤 유지 또는 새 가설
└── 부분 유의미 → 2차 지표 포함 종합 판단
```

### 최소 실행 기간 도달
```
조건: 최소 기간 경과 + 최소 샘플 확보
├── 유의성 달성 → 종료, 승자 적용
├── 유의성 미달 + 트렌드 명확 → 기간 연장 (1회)
└── 유의성 미달 + 트렌드 불명확 → 종료, 무승부 판정
```

### 강제 종료 조건
```
├── 한쪽 변형의 CPA가 목표의 200% 초과 → 해당 변형 즉시 중단
├── 예산 상한 도달 → 테스트 종료
└── 외부 변수 발생 (시즌 이벤트, 정책 변경) → 테스트 무효, 재설계
    (TREND_ANALYST가 외부 변수 모니터링)
```

---

## 산출물 템플릿

### A/B 테스트 결과 리포트 (INSIGHT_ANALYST 작성)
```
# A/B 테스트 결과 리포트

## 1. 테스트 개요
- 테스트명: {이름}
- 기간: {시작일} ~ {종료일}
- 테스트 변수: {변수}
- 가설: {가설}
- 1차 지표: {지표}
- 변형 설계: {담당 서브팀/에이전트}
- 채널 실행: {담당 채널 전문가}
- 법적 검수: {CREATIVE_REVIEWER PASS 여부 (크리에이티브 테스트 시)}

## 2. 결과 요약
| | 변형 A (컨트롤) | 변형 B (챌린저) | 차이 | 유의성 |
|---|---|---|---|---|
| 노출 | | | | |
| 클릭 | | | | |
| CTR | | | | |
| 전환 | | | | |
| CVR | | | | |
| CPA | | | | |
| 비용 | | | | |

## 3. 승자 판정
- 승자: {변형 A or B}
- 1차 지표 차이: {+/-N%}
- 통계적 유의성: {p-value, 신뢰구간}
- 신뢰도: {%}%

## 4. 인사이트
- {왜 이 변형이 이겼는지 분석 (INSIGHT_ANALYST + 담당 서브팀)}
- {타 지표에 미친 영향}
- {향후 적용 시 주의사항}

## 5. 적용 계획
- 승자 변형 전체 적용 일정 (해당 채널 전문가 실행)
- 다음 테스트 제안

## 6. 학습 사항
- {이번 테스트에서 배운 것}
- {다음 테스트에 반영할 것}
```

---

## 테스트 아카이빙

모든 A/B 테스트 결과는 `archive/ab_test_history.md`에 기록하여 누적 학습 자산으로 활용한다.
**INSIGHT_ANALYST**가 테스트 종료 시 아카이브에 자동 기록한다.

```
| 테스트일 | 테스트 변수 | 담당 | 가설 | 승자 | 1차 지표 차이 | 유의성 | 학습 |
|---------|-----------|------|------|------|-------------|--------|------|
```

---

## 참고 파일

| 파일 | 용도 |
|------|------|
| `config/kpi_definitions.md` | KPI 정의, 측정 지표 |
| `workflows/optimization.md` | 최적화 워크플로우 (테스트 결과 반영) |
| `archive/ab_test_history.md` | 과거 테스트 결과 아카이브 |
